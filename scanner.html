<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Detection & Classification</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            margin: 20px;
        }
        .container {
            max-width: 600px;
            margin: auto;
            padding: 20px;
            border: 2px solid #ccc;
            border-radius: 10px;
            background-color: #f9f9f9;
        }
        video {
            width: 100%;
            border: 2px solid #000;
            border-radius: 10px;
            margin-top: 20px;
        }
        button {
            margin: 10px;
            padding: 10px 20px;
            font-size: 18px;
            cursor: pointer;
            border: none;
            border-radius: 5px;
        }
        button.start {
            background-color: #4CAF50;
            color: white;
        }
        button.stop {
            background-color: #d9534f;
            color: white;
        }
        .response {
            margin-top: 20px;
            font-size: 20px;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Face Detection & Classification</h1>
        <p>Click "Start" to scan for a face. The system will classify it as human or something else.</p>
        <video id="webcam" autoplay></video>
        <button class="start" onclick="startScanning()">Start Scanning</button>
        <button class="stop" onclick="stopScanning()">Stop Scanning</button>
        <div class="response" id="response"></div>
    </div>

    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <script>
        const videoElement = document.getElementById("webcam");
        const responseDiv = document.getElementById("response");
        let stream = null;
        let detectInterval;

        // Load the face-api.js models
        async function loadModels() {
            await faceapi.nets.ssdMobilenetv1.loadFromUri('/models');
            await faceapi.nets.faceLandmark68Net.loadFromUri('/models');
            await faceapi.nets.faceRecognitionNet.loadFromUri('/models');
        }

        // Function to start the webcam and detect faces
        async function startScanning() {
            try {
                // Request access to the webcam
                stream = await navigator.mediaDevices.getUserMedia({ video: true });
                videoElement.srcObject = stream;

                // Start the face detection process once the models are loaded
                await loadModels();

                detectInterval = setInterval(async () => {
                    const detections = await faceapi.detectAllFaces(videoElement, new faceapi.SsdMobilenetv1Options()).withFaceLandmarks().withFaceDescriptors();

                    if (detections.length > 0) {
                        responseDiv.textContent = "Human face detected!";
                    } else {
                        responseDiv.textContent = "No face detected, or not a human face.";
                    }
                }, 100);
            } catch (error) {
                alert("Error accessing the webcam: " + error.message);
            }
        }

        // Function to stop the webcam
        function stopScanning() {
            if (stream) {
                // Stop all video tracks
                const tracks = stream.getTracks();
                tracks.forEach(track => track.stop());
                videoElement.srcObject = null;
            }
            clearInterval(detectInterval);
        }
    </script>
</body>
</html>
